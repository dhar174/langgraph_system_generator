"""Notebook Composer agent for generating notebook cell specifications."""

from __future__ import annotations

from typing import Any, Dict, List, Optional

from langchain_core.messages import HumanMessage, SystemMessage
from langchain_openai import ChatOpenAI

from langgraph_system_generator.generator.state import CellSpec, NotebookPlan
from langgraph_system_generator.generator.utils import extract_json_from_llm_response
from langgraph_system_generator.patterns import (
    CritiqueLoopPattern,
    RouterPattern,
    SubagentsPattern,
)
from langgraph_system_generator.utils.config import settings


class NotebookComposer:
    """Generates nbformat cell specifications."""

    def __init__(self, model: str | None = None):
        self.llm = ChatOpenAI(model=model or settings.default_model, temperature=0)

    async def compose_notebook(
        self,
        notebook_plan: NotebookPlan,
        workflow_design: Dict[str, Any],
        tools: List[Dict[str, Any]],
        architecture: Dict[str, Any],
    ) -> List[CellSpec]:
        """Generate complete list of notebook cells.

        Args:
            notebook_plan: Notebook structure plan
            workflow_design: Workflow graph design
            tools: Tools specification
            architecture: Architecture selection

        Returns:
            List of CellSpec objects defining all notebook cells
        """
        # Ensure architecture_type is in workflow_design for pattern selection
        if (
            "architecture_type" not in workflow_design
            and "architecture_type" in architecture
        ):
            workflow_design["architecture_type"] = architecture["architecture_type"]

        cells = []

        # Title and intro cells
        cells.extend(
            self._create_intro_cells(notebook_plan, architecture.get("justification"))
        )

        # Installation cells
        cells.extend(self._create_install_cells(tools))

        # Configuration cells
        cells.extend(self._create_config_cells())

        # State definition
        cells.extend(self._create_state_cells(workflow_design))

        # Tool implementations
        if tools:
            cells.extend(self._create_tool_cells(tools))

        # Node implementations
        cells.extend(self._create_node_cells(workflow_design))

        # Graph construction
        cells.extend(self._create_graph_cells(workflow_design))

        # Execution cells
        cells.extend(self._create_execution_cells())

        return cells

    def _create_intro_cells(
        self, plan: NotebookPlan, justification: str | None
    ) -> List[CellSpec]:
        """Create title and introduction cells."""
        title_cell = CellSpec(
            cell_type="markdown",
            content=f"""# {plan.title}

Generated by LangGraph Notebook Foundry

**Architecture**: {plan.architecture_type}  
**Patterns Used**: {', '.join(plan.patterns_used)}
""",
            section="intro",
        )

        overview_cell = CellSpec(
            cell_type="markdown",
            content=f"""## Overview

This notebook implements a LangGraph workflow using the **{plan.architecture_type}** pattern.

### Architecture Justification

{justification or 'Architecture selected based on requirements analysis.'}

### Sections

{chr(10).join([f"1. {section}" for section in plan.sections])}
""",
            section="intro",
        )

        return [title_cell, overview_cell]

    def _create_install_cells(self, tools: List[Dict[str, Any]]) -> List[CellSpec]:
        """Create installation cells."""
        packages = [
            "langgraph",
            "langchain-core",
            "langchain-community",
            "langchain-openai",
        ]

        # Add tool-specific packages
        for tool in tools:
            category = tool.get("category", "")
            if "search" in category.lower():
                packages.append("langchain-community")
            elif "file" in category.lower() or "document" in category.lower():
                packages.append("pypdf")

        install_content = f"""# Install required packages
!pip install -q {' '.join(packages)}"""

        return [
            CellSpec(
                cell_type="markdown",
                content="## Installation\n\nInstall the required packages:",
                section="setup",
            ),
            CellSpec(cell_type="code", content=install_content, section="setup"),
        ]

    def _create_config_cells(self) -> List[CellSpec]:
        """Create configuration cells."""
        config_content = """import os
from getpass import getpass

# Configuration
MODEL = "gpt-4o-mini"
MAX_ITERATIONS = 10

# API Keys
if not os.environ.get("OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = getpass("Enter OpenAI API Key: ")

if not os.environ.get("ANTHROPIC_API_KEY"):
    os.environ["ANTHROPIC_API_KEY"] = getpass("Enter Anthropic API Key (optional): ")"""

        return [
            CellSpec(
                cell_type="markdown",
                content="## Configuration\n\nSet up API keys and configuration:",
                section="setup",
            ),
            CellSpec(cell_type="code", content=config_content, section="setup"),
        ]

    def _create_state_cells(self, workflow_design: Dict[str, Any]) -> List[CellSpec]:
        """Create state definition cells using pattern library or custom generation."""
        architecture_type = workflow_design.get("architecture_type", "router")
        state_schema = workflow_design.get("state_schema", {})

        # Use pattern library for known architectures
        if architecture_type == "router":
            state_content = RouterPattern.generate_state_code(state_schema)
        elif architecture_type == "subagents":
            state_content = SubagentsPattern.generate_state_code(state_schema)
        elif architecture_type == "critique_loop":
            state_content = CritiqueLoopPattern.generate_state_code(state_schema)
        else:
            # Fallback to custom state generation
            fields = "\n    ".join(
                [f"{name}: str  # {desc}" for name, desc in state_schema.items()]
            )
            state_content = f"""from langgraph.graph import MessagesState


class WorkflowState(MessagesState):
    \"\"\"Custom workflow state schema.
    
    Inherits from MessagesState to maintain conversation history.
    \"\"\"
    {fields if fields else "pass"}"""

        return [
            CellSpec(
                cell_type="markdown",
                content="## State Schema\n\nDefine the workflow state:",
                section="state",
            ),
            CellSpec(cell_type="code", content=state_content, section="state"),
        ]

    def _create_tool_cells(self, tools: List[Dict[str, Any]]) -> List[CellSpec]:
        """Create tool implementation cells with LLM-generated code."""
        cells = [
            CellSpec(
                cell_type="markdown",
                content="## Tools\n\nDefine tools used in the workflow:",
                section="tools",
            )
        ]

        for tool in tools:
            # Try to generate real implementation with LLM
            tool_code = self._generate_tool_implementation(tool)

            cells.append(CellSpec(cell_type="code", content=tool_code, section="tools"))

        return cells

    def _generate_tool_implementation(self, tool: Dict[str, Any]) -> str:
        """Generate tool implementation using LLM.

        Args:
            tool: Tool specification with name, purpose, category, etc.

        Returns:
            Python code string implementing the tool
        """
        tool_name = tool.get("name", "unknown_tool")
        tool_purpose = tool.get("purpose", "")
        tool_category = tool.get("category", "")
        tool_config = tool.get("configuration", {})

        # Create function name
        func_name = tool_name.lower().replace(" ", "_").replace("-", "_")

        try:
            # Build prompt for LLM
            system_prompt = SystemMessage(
                content="""You are an expert Python developer specializing in LangGraph workflows and tool implementations.

Generate a complete, production-ready Python function implementation for the specified tool.

Requirements:
- The function should be fully implemented (no 'pass' statements)
- Include proper error handling
- Add helpful docstrings
- Import necessary libraries at the function level
- Use best practices for the tool's category
- Make it immediately runnable

Common tool categories and approaches:
- **search**: Use DuckDuckGoSearchRun or similar
- **file I/O**: Use pathlib, open(), json, csv libraries
- **data processing**: Use pandas, json, or built-in Python
- **API calls**: Use requests or httpx
- **validation**: Use pydantic or custom validation logic

Return ONLY the Python function code, nothing else."""
            )

            user_prompt = HumanMessage(
                content=f"""Tool Name: {tool_name}
Purpose: {tool_purpose}
Category: {tool_category}
Configuration: {tool_config}

Generate the complete Python function implementation."""
            )

            # Get LLM response (synchronous)
            response = self.llm.invoke([system_prompt, user_prompt])
            generated_code = response.content.strip()

            # Clean up code (remove markdown code blocks if present)
            if generated_code.startswith("```python"):
                generated_code = generated_code[9:]
            if generated_code.startswith("```"):
                generated_code = generated_code[3:]
            if generated_code.endswith("```"):
                generated_code = generated_code[:-3]

            generated_code = generated_code.strip()

            # Add header comment
            header = f"""# Tool: {tool_name}
# Purpose: {tool_purpose}
# Category: {tool_category}

"""
            return header + generated_code

        except (ValueError, KeyError, AttributeError) as e:
            # Fallback to template with better implementation hints
            # Log error for debugging (optional: add logger if available)
            return self._generate_tool_fallback(tool)
        except Exception as e:
            # Unexpected error - still fallback but this is unusual
            return self._generate_tool_fallback(tool)

    def _generate_tool_fallback(self, tool: Dict[str, Any]) -> str:
        """Generate a fallback tool implementation with helpful hints.

        Args:
            tool: Tool specification

        Returns:
            Python code with implementation hints
        """
        tool_name = tool.get("name", "unknown_tool")
        tool_purpose = tool.get("purpose", "")
        tool_category = tool.get("category", "").lower()
        func_name = tool_name.lower().replace(" ", "_").replace("-", "_")

        # Provide category-specific implementation hints
        implementation_hint = ""
        if "search" in tool_category:
            implementation_hint = """    # Example implementation for search:
    # from langchain_community.tools import DuckDuckGoSearchRun
    # search = DuckDuckGoSearchRun()
    # results = search.run(query)
    # return results"""
        elif "file" in tool_category or "document" in tool_category:
            implementation_hint = """    # Example implementation for file operations:
    # from pathlib import Path
    # file_path = Path(filename)
    # content = file_path.read_text()
    # return content"""
        elif "data" in tool_category or "process" in tool_category:
            implementation_hint = """    # Example implementation for data processing:
    # import pandas as pd
    # df = pd.DataFrame(data)
    # processed = df.apply(some_function)
    # return processed.to_dict()"""
        elif "api" in tool_category:
            implementation_hint = """    # Example implementation for API calls:
    # import requests
    # response = requests.get(api_url, params=params)
    # return response.json()"""
        else:
            implementation_hint = """    # Implement your tool logic here
    # Return appropriate results"""

        return f"""# Tool: {tool_name}
# Purpose: {tool_purpose}
# Category: {tool_category}

def {func_name}(*args, **kwargs):
    \"\"\"
    {tool_purpose}
    
    TODO: Implement the actual tool logic.
    \"\"\"
{implementation_hint}
    pass"""

    def _create_node_cells(self, workflow_design: Dict[str, Any]) -> List[CellSpec]:
        """Create node implementation cells with LLM-generated or pattern-based code."""
        cells = [
            CellSpec(
                cell_type="markdown",
                content="## Nodes\n\nImplement workflow nodes:",
                section="nodes",
            )
        ]

        nodes = workflow_design.get("nodes", [])
        architecture_type = workflow_design.get("architecture_type", "router")

        # Check if we should use pattern-based generation
        if architecture_type in ["router", "subagents", "critique_loop"]:
            # Use pattern library for architecture-specific nodes
            pattern_cells = self._generate_nodes_from_pattern(
                nodes, architecture_type, workflow_design
            )
            cells.extend(pattern_cells)
        else:
            # Use LLM for custom node generation
            for node in nodes:
                node_code = self._generate_node_implementation(node, workflow_design)
                cells.append(
                    CellSpec(cell_type="code", content=node_code, section="nodes")
                )

        return cells

    def _generate_node_implementation(
        self, node: Dict[str, Any], workflow_design: Dict[str, Any]
    ) -> str:
        """Generate node implementation using LLM.

        Args:
            node: Node specification with name, purpose, etc.
            workflow_design: Complete workflow design for context

        Returns:
            Python code string implementing the node
        """
        node_name = node.get("name", "unknown")
        node_purpose = node.get("purpose", "")
        state_schema = workflow_design.get("state_schema", {})

        try:
            # Build prompt for LLM
            system_prompt = SystemMessage(
                content="""You are an expert Python developer specializing in LangGraph node implementations.

Generate a complete, production-ready Python function for a LangGraph node.

Requirements:
- Function signature: def {node_name}_node(state: WorkflowState) -> WorkflowState
- The function MUST return an updated state dictionary (not just 'return state')
- Include proper LLM initialization and invocation if needed
- Use MessagesState pattern with proper message handling
- Import necessary libraries at the function level
- Add comprehensive docstring
- Implement actual logic based on the purpose (no 'pass' statements)
- Handle state fields appropriately

Return ONLY the Python function code, nothing else."""
            )

            state_info = "\n".join(
                [f"- {field}: {desc}" for field, desc in state_schema.items()]
            )

            user_prompt = HumanMessage(
                content=f"""Node Name: {node_name}
Purpose: {node_purpose}

State Schema:
{state_info}

Generate the complete Python function implementation."""
            )

            # Get LLM response
            response = self.llm.invoke([system_prompt, user_prompt])
            generated_code = response.content.strip()

            # Clean up code
            if generated_code.startswith("```python"):
                generated_code = generated_code[9:]
            if generated_code.startswith("```"):
                generated_code = generated_code[3:]
            if generated_code.endswith("```"):
                generated_code = generated_code[:-3]

            generated_code = generated_code.strip()

            return generated_code

        except (ValueError, KeyError, AttributeError) as e:
            # Fallback to improved template
            return self._generate_node_fallback(node, workflow_design)
        except Exception as e:
            # Unexpected error - still fallback
            return self._generate_node_fallback(node, workflow_design)

    def _generate_node_fallback(
        self, node: Dict[str, Any], workflow_design: Dict[str, Any]
    ) -> str:
        """Generate fallback node implementation with helpful hints.

        Args:
            node: Node specification
            workflow_design: Workflow design for context

        Returns:
            Python code with implementation hints
        """
        node_name = node.get("name", "unknown")
        node_purpose = node.get("purpose", "")

        return f"""def {node_name}_node(state: WorkflowState) -> WorkflowState:
    \"\"\"
    {node_purpose}
    
    TODO: Implement the actual node logic.
    \"\"\"
    from langchain_openai import ChatOpenAI
    from langchain_core.messages import HumanMessage
    
    messages = state["messages"]
    
    # Example LLM-based implementation:
    # llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    # response = llm.invoke(messages)
    # 
    # return {{
    #     **state,
    #     "messages": messages + [response],
    # }}
    
    # Implement node logic here
    return state"""

    def _generate_nodes_from_pattern(
        self,
        nodes: List[Dict[str, Any]],
        architecture_type: str,
        workflow_design: Dict[str, Any],
    ) -> List[CellSpec]:
        """Generate nodes using pattern library templates.

        Args:
            nodes: List of node specifications
            architecture_type: Architecture pattern type
            workflow_design: Complete workflow design

        Returns:
            List of CellSpec objects with pattern-based node implementations
        """
        cells = []

        if architecture_type == "router":
            # Extract routes from nodes
            routes = [
                node.get("name") for node in nodes if node.get("name") != "router"
            ]

            # Generate router node
            router_code = RouterPattern.generate_router_node_code(routes)
            cells.append(
                CellSpec(cell_type="code", content=router_code, section="nodes")
            )

            # Generate route handler nodes
            for node in nodes:
                if node.get("name") != "router":
                    route_code = RouterPattern.generate_route_node_code(
                        node.get("name"),
                        node.get("purpose", f"Handle {node.get('name')} requests"),
                    )
                    cells.append(
                        CellSpec(cell_type="code", content=route_code, section="nodes")
                    )

        elif architecture_type == "subagents":
            # Extract subagents (excluding supervisor)
            subagents = [
                node.get("name") for node in nodes if node.get("name") != "supervisor"
            ]
            subagent_descriptions = {
                node.get("name"): node.get("purpose", "")
                for node in nodes
                if node.get("name") != "supervisor"
            }

            # Generate supervisor node
            supervisor_code = SubagentsPattern.generate_supervisor_code(
                subagents, subagent_descriptions
            )
            cells.append(
                CellSpec(cell_type="code", content=supervisor_code, section="nodes")
            )

            # Generate subagent nodes
            for node in nodes:
                if node.get("name") != "supervisor":
                    subagent_code = SubagentsPattern.generate_subagent_code(
                        node.get("name"),
                        node.get("purpose", f"{node.get('name')} specialist"),
                    )
                    cells.append(
                        CellSpec(
                            cell_type="code", content=subagent_code, section="nodes"
                        )
                    )

        elif architecture_type == "critique_loop":
            # Generate critique loop nodes
            generate_code = CritiqueLoopPattern.generate_generation_node_code()
            cells.append(
                CellSpec(cell_type="code", content=generate_code, section="nodes")
            )

            critique_code = CritiqueLoopPattern.generate_critique_node_code()
            cells.append(
                CellSpec(cell_type="code", content=critique_code, section="nodes")
            )

            revise_code = CritiqueLoopPattern.generate_revise_node_code()
            cells.append(
                CellSpec(cell_type="code", content=revise_code, section="nodes")
            )

        return cells

    def _create_graph_cells(self, workflow_design: Dict[str, Any]) -> List[CellSpec]:
        """Create graph construction cells using pattern library or custom generation."""
        architecture_type = workflow_design.get("architecture_type", "router")
        nodes = workflow_design.get("nodes", [])

        # Use pattern library for known architectures
        if architecture_type == "router":
            routes = [
                node.get("name") for node in nodes if node.get("name") != "router"
            ]
            graph_code = RouterPattern.generate_graph_code(routes)
        elif architecture_type == "subagents":
            subagents = [
                node.get("name") for node in nodes if node.get("name") != "supervisor"
            ]
            graph_code = SubagentsPattern.generate_graph_code(subagents)
        elif architecture_type == "critique_loop":
            graph_code = CritiqueLoopPattern.generate_graph_code(
                max_revisions=3, min_quality_score=0.8
            )
        else:
            # Fallback to enhanced template-based generation
            graph_code = self._generate_graph_fallback(workflow_design)

        return [
            CellSpec(
                cell_type="markdown",
                content="## Graph Construction\n\nBuild the LangGraph workflow:",
                section="graph",
            ),
            CellSpec(cell_type="code", content=graph_code, section="graph"),
        ]

    def _generate_graph_fallback(self, workflow_design: Dict[str, Any]) -> str:
        """Generate fallback graph construction code.

        Args:
            workflow_design: Complete workflow design

        Returns:
            Python code for graph construction
        """
        entry_point = workflow_design.get("entry_point", "start")
        nodes = workflow_design.get("nodes", [])
        edges = workflow_design.get("edges", [])
        conditional_edges = workflow_design.get("conditional_edges", [])

        # Generate node additions
        node_additions = "\n".join(
            [
                f'workflow.add_node("{node.get("name")}", {node.get("name")}_node)'
                for node in nodes
            ]
        )

        # Generate regular edges
        edge_additions = "\n".join(
            [
                f'workflow.add_edge("{edge.get("from")}", "{edge.get("to")}")'
                for edge in edges
            ]
        )

        # Generate conditional edges if present
        conditional_code = ""
        if conditional_edges:
            conditional_code = "\n\n# Add conditional edges\n" + "\n".join(
                [
                    f'# TODO: Implement conditional logic for {ce.get("from")}'
                    for ce in conditional_edges
                ]
            )

        return f"""from langgraph.graph import END, START, StateGraph
from langgraph.checkpoint.memory import MemorySaver

# Create graph
workflow = StateGraph(WorkflowState)
memory = MemorySaver()

# Add nodes
{node_additions if node_additions else "# Add your nodes here"}

# Connect start to entry point
workflow.add_edge(START, "{entry_point}")

# Add edges
{edge_additions if edge_additions else "# Add your edges here"}
{conditional_code}

# Compile graph
graph = workflow.compile(checkpointer=memory)"""

    def _create_execution_cells(self) -> List[CellSpec]:
        """Create execution cells."""
        exec_content = """# Execute the workflow with a durable thread
config = {"configurable": {"thread_id": "lnf-demo-thread"}}
initial_state: WorkflowState = {
    "messages": [],
    # Configure additional workflow state fields as needed
}

print("Streaming state updates:")
for step in graph.stream(initial_state, config, stream_mode="updates"):
    print(step)

final_state = graph.invoke(initial_state, config)
print(final_state)"""

        return [
            CellSpec(
                cell_type="markdown",
                content="## Execution\n\nRun the workflow:",
                section="execution",
            ),
            CellSpec(cell_type="code", content=exec_content, section="execution"),
        ]
